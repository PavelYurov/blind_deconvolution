{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blind Deconvolution with FunSearch\n",
    "\n",
    "This notebook demonstrates using FunSearch to evolve stopping criteria for the Lucy-Richardson blind deconvolution algorithm.\n",
    "\n",
    "## Problem Description\n",
    "\n",
    "Blind deconvolution aims to recover a sharp image from a blurred observation when the blur kernel (point spread function) is unknown or imperfectly known. The Lucy-Richardson algorithm is an iterative method that can restore images, but determining when to stop the iterations is crucial for balancing image quality with computational efficiency.\n",
    "\n",
    "**FunSearch Goal**: Discover optimal stopping criteria that maximize image quality while minimizing unnecessary iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from typing import Dict, Tuple, Callable\n",
    "\n",
    "# If running in Colab, install required packages\n",
    "try:\n",
    "    import google.colab\n",
    "    !pip install scipy matplotlib numpy\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Algorithm Implementation\n",
    "\n",
    "The following code implements the Lucy-Richardson deconvolution algorithm and supporting utilities. This is the program skeleton that FunSearch will evolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_image(size: int = 64) -> np.ndarray:\n",
    "    \"\"\"Generate a synthetic test image with clear features.\"\"\"\n",
    "    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))\n",
    "    \n",
    "    image = np.zeros((size, size))\n",
    "    image += 0.5 * np.exp(-(x**2 + y**2) / 0.2)\n",
    "    image += 0.3 * np.sin(8 * np.pi * x) * np.exp(-y**2 / 0.1)\n",
    "    image += 0.2 * np.sin(8 * np.pi * y) * np.exp(-x**2 / 0.1)\n",
    "    \n",
    "    image[size//4, size//4] += 0.8\n",
    "    image[3*size//4, 3*size//4] += 0.6\n",
    "    \n",
    "    return np.clip(image, 0, 1)\n",
    "\n",
    "\n",
    "def generate_blur_kernel(kernel_type: str, size: int = 15) -> np.ndarray:\n",
    "    \"\"\"Generate different types of blur kernels.\"\"\"\n",
    "    if kernel_type == \"gaussian\":\n",
    "        sigma = size / 6\n",
    "        kernel = np.zeros((size, size))\n",
    "        center = size // 2\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                kernel[i, j] = np.exp(-((i - center)**2 + (j - center)**2) / (2 * sigma**2))\n",
    "        return kernel / np.sum(kernel)\n",
    "    \n",
    "    elif kernel_type == \"motion\":\n",
    "        kernel = np.zeros((size, size))\n",
    "        center = size // 2\n",
    "        length = size // 2\n",
    "        for i in range(length):\n",
    "            kernel[center, center - length//2 + i] = 1\n",
    "        return kernel / np.sum(kernel)\n",
    "    \n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "\n",
    "def lucy_richardson_iteration(current_estimate: np.ndarray, \n",
    "                            observed_image: np.ndarray,\n",
    "                            psf: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Single Lucy-Richardson iteration.\"\"\"\n",
    "    convolved = signal.convolve2d(current_estimate, psf, mode='same', boundary='symm')\n",
    "    convolved = np.maximum(convolved, 1e-10)\n",
    "    ratio = observed_image / convolved\n",
    "    psf_flipped = np.flipud(np.fliplr(psf))\n",
    "    correction = signal.convolve2d(ratio, psf_flipped, mode='same', boundary='symm')\n",
    "    return current_estimate * correction\n",
    "\n",
    "\n",
    "def compute_psnr(image1: np.ndarray, image2: np.ndarray) -> float:\n",
    "    \"\"\"Compute Peak Signal-to-Noise Ratio between two images.\"\"\"\n",
    "    mse = np.mean((image1 - image2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(1.0 / np.sqrt(mse))\n",
    "\n",
    "\n",
    "def compute_image_gradient_norm(image: np.ndarray) -> float:\n",
    "    \"\"\"Compute the L2 norm of the image gradient.\"\"\"\n",
    "    grad_x = np.gradient(image, axis=1)\n",
    "    grad_y = np.gradient(image, axis=0)\n",
    "    return np.sqrt(np.mean(grad_x**2 + grad_y**2))\n",
    "\n",
    "\n",
    "def compute_residual_norm(current: np.ndarray, previous: np.ndarray) -> float:\n",
    "    \"\"\"Compute normalized change between iterations.\"\"\"\n",
    "    diff = np.abs(current - previous)\n",
    "    return np.mean(diff) / (np.mean(np.abs(current)) + 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FunSearch Specification\n",
    "\n",
    "The commented-out decorators are just a way to indicate the main entry point of the program (`@funsearch.run`) and the function that *FunSearch* should evolve (`@funsearch.evolve`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @funsearch.run\n",
    "def evaluate(test_cases: Dict[str, Dict]) -> float:\n",
    "    \"\"\"Evaluate the convergence criteria across multiple test cases.\n",
    "    \n",
    "    Args:\n",
    "        test_cases: Dictionary of test scenarios with ground truth images,\n",
    "                   blur kernels, and observed (blurred) images.\n",
    "    \n",
    "    Returns:\n",
    "        Composite score based on quality, efficiency, and stability.\n",
    "    \"\"\"\n",
    "    total_score = 0.0\n",
    "    num_cases = 0\n",
    "    \n",
    "    for case_name, case_data in test_cases.items():\n",
    "        ground_truth = case_data['ground_truth']\n",
    "        observed = case_data['observed']\n",
    "        psf = case_data['psf']\n",
    "        \n",
    "        # Run Lucy-Richardson with evolved stopping criteria\n",
    "        deconvolved, iterations_used, _ = run_lucy_richardson_with_stopping(\n",
    "            observed, psf, ground_truth, max_iterations=100\n",
    "        )\n",
    "        \n",
    "        # Quality metric (PSNR)\n",
    "        psnr = compute_psnr(ground_truth, deconvolved)\n",
    "        quality_score = min(psnr / 30.0, 1.0)  # Normalize, cap at 30dB\n",
    "        \n",
    "        # Efficiency metric (fewer iterations is better)\n",
    "        efficiency_score = max(0, 1.0 - iterations_used / 100.0)\n",
    "        \n",
    "        # Stability metric (penalize extreme iteration counts)\n",
    "        stability_penalty = 0.1 if iterations_used < 5 or iterations_used > 80 else 0.0\n",
    "        \n",
    "        # Composite score for this case\n",
    "        case_score = 0.6 * quality_score + 0.3 * efficiency_score - stability_penalty\n",
    "        total_score += max(case_score, 0.0)\n",
    "        num_cases += 1\n",
    "    \n",
    "    return total_score / num_cases if num_cases > 0 else 0.0\n",
    "\n",
    "\n",
    "def run_lucy_richardson_with_stopping(\n",
    "    observed_image: np.ndarray,\n",
    "    psf: np.ndarray, \n",
    "    ground_truth: np.ndarray,\n",
    "    max_iterations: int = 100\n",
    ") -> Tuple[np.ndarray, int, float]:\n",
    "    \"\"\"Run Lucy-Richardson with evolved stopping criteria.\"\"\"\n",
    "    current_estimate = observed_image.copy()\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        previous_estimate = current_estimate.copy()\n",
    "        current_estimate = lucy_richardson_iteration(current_estimate, observed_image, psf)\n",
    "        \n",
    "        # Use evolved stopping criteria\n",
    "        if should_stop(current_estimate, previous_estimate, iteration, psf, observed_image):\n",
    "            final_psnr = compute_psnr(ground_truth, current_estimate)\n",
    "            return current_estimate, iteration + 1, final_psnr\n",
    "    \n",
    "    # Max iterations reached\n",
    "    final_psnr = compute_psnr(ground_truth, current_estimate)\n",
    "    return current_estimate, max_iterations, final_psnr\n",
    "\n",
    "\n",
    "# @funsearch.evolve\n",
    "def should_stop(current_image: np.ndarray, \n",
    "               previous_image: np.ndarray, \n",
    "               iteration: int,\n",
    "               blur_kernel: np.ndarray, \n",
    "               observed_image: np.ndarray) -> bool:\n",
    "    \"\"\"Evolved stopping criteria for Lucy-Richardson deconvolution.\n",
    "    \n",
    "    Args:\n",
    "        current_image: Current estimate of the deconvolved image\n",
    "        previous_image: Previous iteration's estimate\n",
    "        iteration: Current iteration number (0-indexed)\n",
    "        blur_kernel: The point spread function used for deconvolution\n",
    "        observed_image: The original blurred/observed image\n",
    "        \n",
    "    Returns:\n",
    "        True if algorithm should stop, False to continue iterating.\n",
    "    \"\"\"\n",
    "    # Trivial initial implementation - stop after fixed iterations\n",
    "    return iteration >= 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Demonstration\n",
    "\n",
    "Let's create test cases and visualize the deconvolution process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test cases\n",
    "def create_test_cases() -> Dict[str, Dict]:\n",
    "    \"\"\"Create a set of test cases for blind deconvolution.\"\"\"\n",
    "    test_cases = {}\n",
    "    \n",
    "    # Test case 1: Gaussian blur\n",
    "    ground_truth_1 = generate_test_image(64)\n",
    "    gaussian_kernel = generate_blur_kernel(\"gaussian\", 15)\n",
    "    observed_1 = signal.convolve2d(ground_truth_1, gaussian_kernel, mode='same', boundary='symm')\n",
    "    observed_1 = np.clip(observed_1 + np.random.normal(0, 0.01, observed_1.shape), 0, 1)\n",
    "    \n",
    "    test_cases['gaussian_blur'] = {\n",
    "        'ground_truth': ground_truth_1,\n",
    "        'observed': observed_1,\n",
    "        'psf': gaussian_kernel\n",
    "    }\n",
    "    \n",
    "    # Test case 2: Motion blur\n",
    "    ground_truth_2 = generate_test_image(64)\n",
    "    motion_kernel = generate_blur_kernel(\"motion\", 15)\n",
    "    observed_2 = signal.convolve2d(ground_truth_2, motion_kernel, mode='same', boundary='symm')\n",
    "    observed_2 = np.clip(observed_2 + np.random.normal(0, 0.01, observed_2.shape), 0, 1)\n",
    "    \n",
    "    test_cases['motion_blur'] = {\n",
    "        'ground_truth': ground_truth_2,\n",
    "        'observed': observed_2,\n",
    "        'psf': motion_kernel\n",
    "    }\n",
    "    \n",
    "    return test_cases\n",
    "\n",
    "\n",
    "# Create test cases\n",
    "test_cases = create_test_cases()\n",
    "\n",
    "# Evaluate the current (trivial) stopping criteria\n",
    "score = evaluate(test_cases)\n",
    "print(f\"Current score with trivial stopping criteria: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one test case\n",
    "case_data = test_cases['gaussian_blur']\n",
    "ground_truth = case_data['ground_truth']\n",
    "observed = case_data['observed']\n",
    "psf = case_data['psf']\n",
    "\n",
    "# Run deconvolution\n",
    "deconvolved, iterations_used, final_psnr = run_lucy_richardson_with_stopping(\n",
    "    observed, psf, ground_truth, max_iterations=100\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].imshow(ground_truth, cmap='gray')\n",
    "axes[0, 0].set_title('Ground Truth')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(observed, cmap='gray')\n",
    "axes[0, 1].set_title('Blurred + Noise')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(deconvolved, cmap='gray')\n",
    "axes[0, 2].set_title(f'Deconvolved\\n({iterations_used} iterations)')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(psf, cmap='gray')\n",
    "axes[1, 0].set_title('Blur Kernel')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Show residual\n",
    "residual = np.abs(deconvolved - ground_truth)\n",
    "axes[1, 1].imshow(residual, cmap='hot')\n",
    "axes[1, 1].set_title(f'Error Map\\nPSNR: {final_psnr:.2f}dB')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Show convergence over iterations\n",
    "psnr_history = []\n",
    "current_est = observed.copy()\n",
    "for i in range(min(iterations_used + 10, 60)):\n",
    "    current_est = lucy_richardson_iteration(current_est, observed, psf)\n",
    "    psnr_history.append(compute_psnr(ground_truth, current_est))\n",
    "\n",
    "axes[1, 2].plot(psnr_history)\n",
    "axes[1, 2].axvline(x=iterations_used-1, color='red', linestyle='--', label='Stopping point')\n",
    "axes[1, 2].set_xlabel('Iteration')\n",
    "axes[1, 2].set_ylabel('PSNR (dB)')\n",
    "axes[1, 2].set_title('Convergence')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final PSNR: {final_psnr:.2f} dB\")\n",
    "print(f\"Iterations used: {iterations_used}\")\n",
    "print(f\"Overall evaluation score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How FunSearch Will Improve This\n",
    "\n",
    "FunSearch will evolve the `should_stop` function to discover better stopping criteria. Some potential discoveries might include:\n",
    "\n",
    "1. **Gradient-based stopping**: Stop when image gradients stabilize\n",
    "2. **Residual analysis**: Stop when iteration-to-iteration changes fall below adaptive thresholds\n",
    "3. **Multi-scale convergence**: Different criteria for different frequency components\n",
    "4. **Blur-kernel-aware stopping**: Adapt criteria based on estimated PSF properties\n",
    "5. **Quality-efficiency trade-offs**: Dynamic balancing based on iteration count and improvement rate\n",
    "\n",
    "The evolved functions should significantly outperform the trivial fixed-iteration stopping criterion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}